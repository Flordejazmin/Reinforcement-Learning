% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
\usepackage{colortbl}
\usepackage{array}
\usepackage{anyfontsize}
\usepackage{multirow}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Reinforcement Learning},
  pdfauthor={Norah Jones},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Reinforcement Learning}
\author{Norah Jones}
\date{Invalid Date}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

\bookmarksetup{startatroot}

\chapter{Activate the Core Packages}\label{activate-the-core-packages}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(bibtex)}
\FunctionTok{library}\NormalTok{(tidyverse) }\DocumentationTok{\#\# Brings in a core of useful functions}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
v dplyr     1.1.4     v readr     2.1.5
v forcats   1.0.0     v stringr   1.5.1
v ggplot2   3.5.1     v tibble    3.2.1
v lubridate 1.9.3     v tidyr     1.3.1
v purrr     1.0.2     
-- Conflicts ------------------------------------------ tidyverse_conflicts() --
x dplyr::filter() masks stats::filter()
x dplyr::lag()    masks stats::lag()
i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gt)        }\DocumentationTok{\#\# Tables}
\DocumentationTok{\#\# Specific packages}
\FunctionTok{library}\NormalTok{(milestones)}
\DocumentationTok{\#\# Initialize defaults}
\DocumentationTok{\#\# Initialize defaults}
\NormalTok{column }\OtherTok{\textless{}{-}} \FunctionTok{lolli\_styles}\NormalTok{()}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\AttributeTok{col\_names=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{show\_col\_types=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{file=}\StringTok{\textquotesingle{}rl\_time\_line.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Sort the table by date}
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(date)}

\DocumentationTok{\#\# Build a table}
\FunctionTok{gt}\NormalTok{(data) }\SpecialCharTok{|\textgreater{}}
  \CommentTok{\#cols\_hide(columns = event) |\textgreater{}}
  \FunctionTok{tab\_style}\NormalTok{(}\FunctionTok{cell\_text}\NormalTok{(}\AttributeTok{v\_align =} \StringTok{"top"}\NormalTok{),}
            \AttributeTok{locations =} \FunctionTok{cells\_body}\NormalTok{(}\AttributeTok{columns =}\NormalTok{ date)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tab\_source\_note}\NormalTok{(}\AttributeTok{source\_note =} \StringTok{"Source: Sutton and Barto (2018)"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begingroup
\fontsize{12.0pt}{14.4pt}\selectfont
\setlength{\LTpost}{0mm}
\begin{longtable*}{rll}
\toprule
date & event & reference \\ 
\midrule\addlinespace[2.5pt]
{1911} & The first idea of "trial-error-learning" emerges. & Thorndike, E. L. (1911). Animal Intelligence. Hafner, Darien, CT. \\ 
{1927} & The term "Reinforcement" appears. & Pavlov, P. I. (1927). Conditioned Re exes. Oxford University Press, London \\ 
{1954} & Important works on "trial-error-learning." & Minsky, M. L. (1954). Theory of Neural-Analog Reinforcement Systems and
 Its Application to the Brain-Model Problem. Ph.D. thesis, Princeton Uni
versity \\ 
{1957} & "Dynamic Programming" appears. & Bellman, R. E. (1957).?Dynamic programming. Princeton University Press. \\ 
{1957} & Markov Decision Processes emerge. & Bellman, R. (1957). A Markovian Decision Process. Indiana University mathematics journal, 6(4), 679?684. https://doi.org/10.1512/iumj.1957.6.56038 \\ 
{1959} & The term "Optimal Control" appears. & NA \\ 
{1959} & Temporal-difference-learning appears. & Samuel, A. L. (1959). Some studies in machine learning using the game
 of checkers.
 IBM Journal on Research and Development, 3:211229.
 Reprinted in E. A. Feigenbaum and J. Feldman (eds.), Computers and
 Thought, pp. 71105. McGraw-Hill, New York, 1963. \\ 
{1960} & The policy iteration method is introduced. & Howard, R. A. (1960). Dynamic programming and Markov processes. MIT Press.
 \\ 
{1960} & The terms "Reinforcement" and "Reinforcement Learning" are used. & Waltz, M. D., Fu, K. S. (1965). A heuristic approach to reinforcement learning
 control systems. IEEE Transactions on Automatic Control, 10:390398. \\ 
{1960} & "Learning Automata" originate. & Tsetlin, M. L. (1973). Automaton Theory and Modeling of Biological Systems.
 Academic Press, New York \\ 
{1961} & Publication of "Steps Toward Artificial Intelligence." & Minsky, M. L. (1961). Steps toward arti cial intelligence. Proceedings of the
 Institute of Radio Engineers, 49:830. Reprinted in E. A. Feigenbaum and
 J. Feldman (eds.), Computers and Thought, pp. 406450. McGraw-Hill,
 New York, 1963. \\ 
{1963} & STeLLA is created. & Andreae, J. H. (1963). STELLA: A scheme for a learning machine. In
 Proceedings of the 2nd IFAC Congress, Basle, pp. 497502. Butterworths,
 London. \\ 
{1972} & Trial-error-learning and temporal-difference-learning are combined. & Klopf, A. H. (1972). Brain function and adaptive systems A heterostatic
 theory. Technical Report AFCRL-72-0164, Air Force Cambridge Research
 Laboratories, Bedford, MA. A summary appears in Proceedings of the In
ternational Conference on Systems, Man, and Cybernetics. IEEE Systems,
 Man, and Cybernetics Society, Dallas, TX, 1974. \\ 
{1977} & Optimal Control and Dynamic Programming are connected. & Werbos, P. J. (1977). Advanced forecasting methods for global crisis warning
 and models of intelligence. General Systems Yearbook, 22:2538. \\ 
{1978} & Sutton develops Klopf's ideas. & Sutton, R. S. (1978a). Learning theory support for a single channel theory of
 the brain. Unpublished report. \\ 
{1986} & Classifiers are introduced. & Holland, J. H. (1986). Escaping brittleness: The possibility of general-purpose
 learning algorithms applied to rule-based systems. In R. S. Michalski,
 J. G. Carbonell, and T. M. Mitchell (eds.), Machine Learning: An Arti cial
 Intelligence Approach, vol. 2, pp. 593623. Morgan Kaufmann, San Mateo,
 CA \\ 
{1989} & Learning methods are integrated. & Watkins, C. J. C. H. (1989). Learning from Delayed Rewards. Ph.D. thesis,
 Cambridge University. \\ 
{2003} & Reinforcement Learning in economics. & Camerer, C. (2003). Behavioral game theory: Experiments in strategic inter
action. Princeton University Press \\ 
{2012} & Reinforcement Learning and Games. & Nowe, A., Vrancx, P., De Hauwere, Y. M. (2012). Game theory and multi
agent reinforcement learning. In Reinforcement Learning (pp. 441-470).
 Springer Berlin Heidelberg \\ 
\bottomrule
\end{longtable*}
\begin{minipage}{\linewidth}
Source: Sutton and Barto (2018)\\
\end{minipage}
\endgroup

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Adjust some defaults}
\NormalTok{column}\SpecialCharTok{$}\NormalTok{color }\OtherTok{\textless{}{-}} \StringTok{"pink"}
\NormalTok{column}\SpecialCharTok{$}\NormalTok{size  }\OtherTok{\textless{}{-}} \DecValTok{15}
\NormalTok{column}\SpecialCharTok{$}\NormalTok{source\_info }\OtherTok{\textless{}{-}} \StringTok{"Source: Sutton and Barto (2018)"}

\DocumentationTok{\#\# Milestones timeline}
\FunctionTok{milestones}\NormalTok{(}\AttributeTok{datatable =}\NormalTok{ data, }\AttributeTok{styles =}\NormalTok{ column)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tarea-1_files/figure-pdf/unnamed-chunk-4-1.pdf}

\section{EJERCICIO 1}\label{ejercicio-1}

En el aprendizaje reforzado un agente aprende a tomar decisiones
(acciones) a través de la interacción con su entorno y recibiendo
recompensas o castigos en función de las mismas, a diferencia del
aprendizaje supervisado, ya que en este tipo de aprendizaje automático,
un modelo se entrena utilizando un conjunto de datos que incluye tanto
las entradas como las salidas correspondientes (etiquetas). es decir,
consiste en aprender a partir\\
de un conjunto de ejemplos ya etiquetados y proporcionados por un
supervisor externo con conocimientos. Por lo que en este tipo de
aprendizaje Cada ejemplo describe una situación especifica, y además
existe una etiqueta que indica la acción adecuada que el sistema debe
tomar en esa situación, El objetivo de este tipo de aprendizaje es que
el\\
sistema generalice sus respuestas para que actúe correctamente en
situaciones que no están presentes en el conjunto de entrenamiento. Por
otra parte El aprendizaje por refuerzo también es diferente de lo que
los investigadores del aprendizaje automático llaman aprendizaje no
supervisado, que generalmente consiste en\\
encontrar estructuras ocultas en conjuntos de datos no etiquetados y
Aunque en parte el aprendizaje por refuerzo es un tipo de aprendizaje no
supervisado, en realidad este se centra mas que nada en maximizar una
recompensa en lugar de buscar patrones ocultos en los datos.

\section{EJERCICIO 2}\label{ejercicio-2}

es posible pensar que dicha expresión es una función con la cual se mide
el desempeño del sistema bajo diferentes políticas de control dado el
estado inicial, es decir, nos ayuda a identificar que acciones fueron
buenas y cuales fueron malas, además dicha expresión nos da el valor
esperado de cuanta recompensa obtendremos en un futuro al elegir dicha
politica dado un estado inicial. Por otra parte, el factor de descuento
en la expresión, nos ayuda a comparar las recompensas futuras con las
recompensas inmediatas, basicamente nos dice que tan a favor estamos de
obtener una recompensa en el estado actual frente a un futuro lejano

\section{APD}\label{apd}

del algoritmo de la programación dinámica se sigue que para este caso
particular \_ \(J_{N}(x)=\beta^{N}(x_N)^{1-\gamma}\)

luego, para \(k= N-1\)
\[J_{N-1}=\min_{a\in A(x)}\{\beta^{N-1}(a)^{1-\gamma} + \beta^{N}(1+r)^{1-\gamma}(x-a)^{1-\gamma}\}\]
derivando con respecto a \(a\) obtenemos
\[(1-\gamma)\beta^{N-1}a^{-\gamma}- \beta^{N}(1+r)^{1-\gamma}(x-a)^{-\gamma}\]
depués igualando a cero
\[(1-\gamma)\beta^{N-1}[a^{-\gamma}-\beta(1+r)^{1-\gamma}(x-a)^{-\gamma}]=0\]
entonces \[(\cfrac{x-a}{a})^\gamma=\beta(1+r)^{1-\gamma}\]
\[\cfrac{x-a}{a}=[\beta(1+r)^{1-\gamma}]^{\frac{1}{\gamma}}\]

\bookmarksetup{startatroot}

\chapter{Summary}\label{summary}

In summary, this book has no content whatsoever.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\bookmarksetup{startatroot}

\chapter*{References}\label{references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\end{CSLReferences}




\end{document}
